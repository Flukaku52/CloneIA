#!/usr/bin/env python3
"""
Script para testar cada novo sample individual conforme for gravado
Fornece feedback imediato sobre qualidade e teste de voz
"""

import os
import sys
import json
import subprocess
import tempfile
import wave
import numpy as np
from pathlib import Path
from datetime import datetime
import argparse

# Adiciona o diretÃ³rio do projeto ao path
sys.path.append(str(Path(__file__).parent))

from core.audio import AudioGenerator
from core.utils import load_voice_config

def extract_audio_from_video(video_path: str, output_path: str) -> bool:
    """Extrai Ã¡udio de vÃ­deo"""
    try:
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn', '-acodec', 'pcm_s16le',
            '-ar', '16000', '-ac', '1',
            output_path, '-y'
        ]
        subprocess.run(cmd, capture_output=True, check=True)
        return True
    except Exception as e:
        print(f"âŒ Erro ao extrair Ã¡udio: {e}")
        return False

def analyze_sample_quality(audio_path: str) -> dict:
    """Analisa qualidade do sample"""
    try:
        with wave.open(audio_path, 'rb') as wav_file:
            frames = wav_file.readframes(-1)
            sound_info = np.frombuffer(frames, dtype=np.int16)
            frame_rate = wav_file.getframerate()
            duration = len(sound_info) / frame_rate
            
            if np.max(np.abs(sound_info)) > 0:
                sound_normalized = sound_info / np.max(np.abs(sound_info))
            else:
                return {}
            
            # MÃ©tricas de qualidade
            signal_to_noise = np.mean(np.abs(sound_normalized)) / (np.std(sound_normalized) + 1e-8)
            silence_threshold = 0.05
            silences = np.abs(sound_normalized) < silence_threshold
            silence_ratio = np.sum(silences) / len(silences)
            
            # RuÃ­do de fundo
            start_noise = np.std(sound_normalized[:int(frame_rate * 0.5)]) if len(sound_normalized) > frame_rate else 0
            end_noise = np.std(sound_normalized[-int(frame_rate * 0.5):]) if len(sound_normalized) > frame_rate else 0
            background_noise = (start_noise + end_noise) / 2
            
            # Clipping
            clipping_ratio = np.sum(np.abs(sound_normalized) > 0.95) / len(sound_normalized)
            
            # VariaÃ§Ã£o dinÃ¢mica
            tonal_variety = np.std(np.diff(sound_normalized))
            
            return {
                'duration': duration,
                'signal_to_noise': float(signal_to_noise),
                'silence_ratio': float(silence_ratio),
                'background_noise': float(background_noise),
                'clipping_ratio': float(clipping_ratio),
                'tonal_variety': float(tonal_variety)
            }
    except Exception as e:
        print(f"âŒ Erro na anÃ¡lise: {e}")
        return {}

def evaluate_sample(analysis: dict) -> dict:
    """Avalia se o sample Ã© adequado para ML"""
    if not analysis:
        return {'approved': False, 'score': 0, 'feedback': ['Falha na anÃ¡lise']}
    
    score = 0
    feedback = []
    issues = []
    
    # DuraÃ§Ã£o (8-30 segundos ideal)
    duration = analysis['duration']
    if 8 <= duration <= 30:
        score += 30
        feedback.append(f"âœ… DuraÃ§Ã£o perfeita: {duration:.1f}s")
    elif 5 <= duration <= 40:
        score += 20
        feedback.append(f"ğŸ“ DuraÃ§Ã£o aceitÃ¡vel: {duration:.1f}s")
    elif duration < 5:
        score -= 20
        issues.append(f"âŒ Muito curto: {duration:.1f}s (mÃ­nimo 8s)")
    else:
        score -= 10
        issues.append(f"âš ï¸ Muito longo: {duration:.1f}s (mÃ¡ximo 30s)")
    
    # RelaÃ§Ã£o sinal/ruÃ­do
    snr = analysis['signal_to_noise']
    if snr > 4:
        score += 25
        feedback.append(f"âœ… Ãudio limpo: S/N = {snr:.2f}")
    elif snr > 2:
        score += 15
        feedback.append(f"ğŸ“Š Ãudio bom: S/N = {snr:.2f}")
    else:
        score -= 15
        issues.append(f"âŒ Ãudio com ruÃ­do: S/N = {snr:.2f} (mÃ­nimo 2.0)")
    
    # Taxa de silÃªncio
    silence = analysis['silence_ratio']
    if 0.05 <= silence <= 0.25:
        score += 20
        feedback.append(f"âœ… Fala contÃ­nua ideal: {silence:.2f} silÃªncio")
    elif silence <= 0.35:
        score += 10
        feedback.append(f"ğŸ“Š Boa continuidade: {silence:.2f} silÃªncio")
    else:
        score -= 15
        issues.append(f"âŒ Muito silÃªncio: {silence:.2f} (mÃ¡ximo 0.25)")
    
    # RuÃ­do de fundo
    noise = analysis['background_noise']
    if noise < 0.02:
        score += 15
        feedback.append("âœ… Sem ruÃ­do de fundo")
    elif noise < 0.05:
        score += 10
        feedback.append("ğŸ“Š Pouco ruÃ­do de fundo")
    else:
        score -= 10
        issues.append(f"âŒ RuÃ­do de fundo detectado: {noise:.3f}")
    
    # DistorÃ§Ã£o/Clipping
    clipping = analysis['clipping_ratio']
    if clipping < 0.01:
        score += 10
        feedback.append("âœ… Sem distorÃ§Ã£o")
    else:
        score -= 20
        issues.append(f"âŒ DistorÃ§Ã£o detectada: {clipping:.3f}")
    
    # VariaÃ§Ã£o tonal
    variety = analysis['tonal_variety']
    if variety > 0.02:
        score += 10
        feedback.append(f"âœ… Boa expressividade: {variety:.3f}")
    else:
        issues.append(f"âš ï¸ Pouca variaÃ§Ã£o tonal: {variety:.3f}")
    
    # ClassificaÃ§Ã£o final
    approved = score >= 60
    
    return {
        'approved': approved,
        'score': max(0, score),
        'feedback': feedback,
        'issues': issues,
        'recommendation': 'APROVADO para ML!' if approved else 'REGRAVE com melhorias'
    }

def test_sample_voice_generation(sample_path: str, test_text: str = None) -> str:
    """Testa geraÃ§Ã£o de voz com o novo sample"""
    if not test_text:
        test_text = "Fala cambada! TÃ´ testando esse novo sample aqui pra ver como ficou a voz."
    
    print(f"\nğŸ¤ Testando geraÃ§Ã£o de voz com o sample...")
    
    # Carrega configuraÃ§Ã£o otimizada
    voice_config = load_voice_config("cambada_optimized")
    if not voice_config:
        voice_config = load_voice_config("ml_optimized")
    if not voice_config:
        voice_config = load_voice_config()
    
    # Inicializa gerador
    audio_gen = AudioGenerator()
    
    # Gera timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"output/audio/teste_sample_{timestamp}.mp3"
    
    try:
        audio_path = audio_gen.generate_audio(test_text, output_path)
        if audio_path and os.path.exists(audio_path):
            file_size = os.path.getsize(audio_path) / 1024
            print(f"âœ… Ãudio de teste gerado: {audio_path}")
            print(f"ğŸ“Š Tamanho: {file_size:.1f} KB")
            return audio_path
        else:
            print("âŒ Falha na geraÃ§Ã£o de Ã¡udio")
            return ""
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return ""

def save_sample_report(sample_path: str, analysis: dict, evaluation: dict) -> str:
    """Salva relatÃ³rio do sample"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"sample_reports/report_{timestamp}.json"
    
    os.makedirs("sample_reports", exist_ok=True)
    
    report = {
        'timestamp': timestamp,
        'sample_path': sample_path,
        'analysis': analysis,
        'evaluation': evaluation,
        'approved': evaluation['approved']
    }
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    return report_path

def main():
    parser = argparse.ArgumentParser(description='Testa novo sample de voz')
    parser.add_argument('sample_path', help='Caminho para o arquivo de Ã¡udio/vÃ­deo')
    parser.add_argument('--text', help='Texto personalizado para teste de voz')
    parser.add_argument('--no-voice-test', action='store_true', help='Pula teste de geraÃ§Ã£o de voz')
    
    args = parser.parse_args()
    
    sample_path = Path(args.sample_path)
    if not sample_path.exists():
        print(f"âŒ Arquivo nÃ£o encontrado: {sample_path}")
        return
    
    print("ğŸ™ï¸ TESTE DE NOVO SAMPLE")
    print("=" * 50)
    print(f"ğŸ“ Arquivo: {sample_path.name}")
    
    # Extrai Ã¡udio se for vÃ­deo
    temp_dir = tempfile.mkdtemp()
    if sample_path.suffix.lower() in ['.mp4', '.mov', '.avi', '.mkv']:
        print("ğŸ¬ Extraindo Ã¡udio do vÃ­deo...")
        audio_path = os.path.join(temp_dir, "sample_audio.wav")
        if not extract_audio_from_video(str(sample_path), audio_path):
            print("âŒ Falha na extraÃ§Ã£o de Ã¡udio")
            return
    elif sample_path.suffix.lower() in ['.wav', '.mp3', '.m4a', '.opus', '.ogg', '.flac', '.aifc', '.aiff']:
        # Converte para WAV se necessÃ¡rio
        audio_path = os.path.join(temp_dir, "sample_audio.wav")
        try:
            cmd = ['ffmpeg', '-i', str(sample_path), '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', audio_path, '-y']
            subprocess.run(cmd, capture_output=True, check=True)
        except Exception as e:
            print(f"âŒ Falha na conversÃ£o de Ã¡udio: {e}")
            return
    else:
        print("âŒ Formato nÃ£o suportado. Use: mp4, mov, avi, mkv, wav, mp3, m4a, opus, ogg, flac, aifc, aiff")
        return
    
    # Analisa qualidade
    print("\nğŸ” Analisando qualidade do sample...")
    analysis = analyze_sample_quality(audio_path)
    
    if not analysis:
        print("âŒ Falha na anÃ¡lise")
        return
    
    # Avalia sample
    evaluation = evaluate_sample(analysis)
    
    # Mostra resultados
    print(f"\nğŸ“Š RESULTADO DA ANÃLISE")
    print("=" * 50)
    print(f"ğŸ¯ Score: {evaluation['score']}/100")
    print(f"ğŸ“‹ Status: {evaluation['recommendation']}")
    
    if evaluation['feedback']:
        print(f"\nâœ… Pontos Positivos:")
        for feedback in evaluation['feedback']:
            print(f"   {feedback}")
    
    if evaluation['issues']:
        print(f"\nâš ï¸ Problemas Encontrados:")
        for issue in evaluation['issues']:
            print(f"   {issue}")
    
    # Teste de voz (se aprovado e solicitado)
    if evaluation['approved'] and not args.no_voice_test:
        print(f"\nğŸµ TESTE DE GERAÃ‡ÃƒO DE VOZ")
        print("=" * 50)
        test_audio = test_sample_voice_generation(str(sample_path), args.text)
        if test_audio:
            print(f"ğŸ§ Escute o resultado e compare com sua voz original!")
    elif not evaluation['approved']:
        print(f"\nğŸ’¡ RECOMENDAÃ‡Ã•ES PARA MELHORAR:")
        print("   â€¢ Grave em ambiente mais silencioso")
        print("   â€¢ Mantenha distÃ¢ncia consistente do microfone")
        print("   â€¢ Fale de forma contÃ­nua, evite pausas longas")
        print("   â€¢ DuraÃ§Ã£o ideal: 10-25 segundos")
        print("   â€¢ Regrave atÃ© conseguir score 60+")
    
    # Salva relatÃ³rio
    report_path = save_sample_report(str(sample_path), analysis, evaluation)
    print(f"\nğŸ“„ RelatÃ³rio salvo em: {report_path}")
    
    if evaluation['approved']:
        print(f"\nğŸ‰ SAMPLE APROVADO! Pode usar para treinar o modelo.")
    else:
        print(f"\nğŸ”„ Regrave seguindo as recomendaÃ§Ãµes acima.")

if __name__ == "__main__":
    main()