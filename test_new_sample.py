#!/usr/bin/env python3
"""
Script para testar cada novo sample individual conforme for gravado
Fornece feedback imediato sobre qualidade e teste de voz
"""

import os
import sys
import json
import subprocess
import tempfile
import wave
import numpy as np
from pathlib import Path
from datetime import datetime
import argparse

# Adiciona o diret√≥rio do projeto ao path
sys.path.append(str(Path(__file__).parent))

from core.audio import AudioGenerator
from core.utils import load_voice_config

def extract_audio_from_video(video_path: str, output_path: str) -> bool:
    """Extrai √°udio de v√≠deo"""
    try:
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn', '-acodec', 'pcm_s16le',
            '-ar', '16000', '-ac', '1',
            output_path, '-y'
        ]
        subprocess.run(cmd, capture_output=True, check=True)
        return True
    except Exception as e:
        print(f"‚ùå Erro ao extrair √°udio: {e}")
        return False

def analyze_sample_quality(audio_path: str) -> dict:
    """Analisa qualidade do sample"""
    try:
        with wave.open(audio_path, 'rb') as wav_file:
            frames = wav_file.readframes(-1)
            sound_info = np.frombuffer(frames, dtype=np.int16)
            frame_rate = wav_file.getframerate()
            duration = len(sound_info) / frame_rate
            
            if np.max(np.abs(sound_info)) > 0:
                sound_normalized = sound_info / np.max(np.abs(sound_info))
            else:
                return {}
            
            # M√©tricas de qualidade
            signal_to_noise = np.mean(np.abs(sound_normalized)) / (np.std(sound_normalized) + 1e-8)
            silence_threshold = 0.05
            silences = np.abs(sound_normalized) < silence_threshold
            silence_ratio = np.sum(silences) / len(silences)
            
            # Ru√≠do de fundo
            start_noise = np.std(sound_normalized[:int(frame_rate * 0.5)]) if len(sound_normalized) > frame_rate else 0
            end_noise = np.std(sound_normalized[-int(frame_rate * 0.5):]) if len(sound_normalized) > frame_rate else 0
            background_noise = (start_noise + end_noise) / 2
            
            # Clipping
            clipping_ratio = np.sum(np.abs(sound_normalized) > 0.95) / len(sound_normalized)
            
            # Varia√ß√£o din√¢mica
            tonal_variety = np.std(np.diff(sound_normalized))
            
            return {
                'duration': duration,
                'signal_to_noise': float(signal_to_noise),
                'silence_ratio': float(silence_ratio),
                'background_noise': float(background_noise),
                'clipping_ratio': float(clipping_ratio),
                'tonal_variety': float(tonal_variety)
            }
    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        return {}

def evaluate_sample(analysis: dict) -> dict:
    """Avalia se o sample √© adequado para ML"""
    if not analysis:
        return {'approved': False, 'score': 0, 'feedback': ['Falha na an√°lise']}
    
    score = 0
    feedback = []
    issues = []
    
    # Dura√ß√£o (8-30 segundos ideal)
    duration = analysis['duration']
    if 8 <= duration <= 30:
        score += 30
        feedback.append(f"‚úÖ Dura√ß√£o perfeita: {duration:.1f}s")
    elif 5 <= duration <= 40:
        score += 20
        feedback.append(f"üìè Dura√ß√£o aceit√°vel: {duration:.1f}s")
    elif duration < 5:
        score -= 20
        issues.append(f"‚ùå Muito curto: {duration:.1f}s (m√≠nimo 8s)")
    else:
        score -= 10
        issues.append(f"‚ö†Ô∏è Muito longo: {duration:.1f}s (m√°ximo 30s)")
    
    # Rela√ß√£o sinal/ru√≠do
    snr = analysis['signal_to_noise']
    if snr > 4:
        score += 25
        feedback.append(f"‚úÖ √Åudio limpo: S/N = {snr:.2f}")
    elif snr > 2:
        score += 15
        feedback.append(f"üìä √Åudio bom: S/N = {snr:.2f}")
    else:
        score -= 15
        issues.append(f"‚ùå √Åudio com ru√≠do: S/N = {snr:.2f} (m√≠nimo 2.0)")
    
    # Taxa de sil√™ncio
    silence = analysis['silence_ratio']
    if 0.05 <= silence <= 0.25:
        score += 20
        feedback.append(f"‚úÖ Fala cont√≠nua ideal: {silence:.2f} sil√™ncio")
    elif silence <= 0.35:
        score += 10
        feedback.append(f"üìä Boa continuidade: {silence:.2f} sil√™ncio")
    else:
        score -= 15
        issues.append(f"‚ùå Muito sil√™ncio: {silence:.2f} (m√°ximo 0.25)")
    
    # Ru√≠do de fundo
    noise = analysis['background_noise']
    if noise < 0.02:
        score += 15
        feedback.append("‚úÖ Sem ru√≠do de fundo")
    elif noise < 0.05:
        score += 10
        feedback.append("üìä Pouco ru√≠do de fundo")
    else:
        score -= 10
        issues.append(f"‚ùå Ru√≠do de fundo detectado: {noise:.3f}")
    
    # Distor√ß√£o/Clipping
    clipping = analysis['clipping_ratio']
    if clipping < 0.01:
        score += 10
        feedback.append("‚úÖ Sem distor√ß√£o")
    else:
        score -= 20
        issues.append(f"‚ùå Distor√ß√£o detectada: {clipping:.3f}")
    
    # Varia√ß√£o tonal
    variety = analysis['tonal_variety']
    if variety > 0.02:
        score += 10
        feedback.append(f"‚úÖ Boa expressividade: {variety:.3f}")
    else:
        issues.append(f"‚ö†Ô∏è Pouca varia√ß√£o tonal: {variety:.3f}")
    
    # Classifica√ß√£o final
    approved = score >= 60
    
    return {
        'approved': approved,
        'score': max(0, score),
        'feedback': feedback,
        'issues': issues,
        'recommendation': 'APROVADO para ML!' if approved else 'REGRAVE com melhorias'
    }

def test_sample_voice_generation(sample_path: str, test_text: str = None) -> str:
    """Testa gera√ß√£o de voz com o novo sample"""
    if not test_text:
        test_text = "Fala cambada! T√¥ testando esse novo sample aqui pra ver como ficou a voz."
    
    print(f"\nüé§ Testando gera√ß√£o de voz com o sample...")
    
    # Carrega configura√ß√£o otimizada
    voice_config = load_voice_config("cambada_optimized")
    if not voice_config:
        voice_config = load_voice_config("ml_optimized")
    if not voice_config:
        voice_config = load_voice_config()
    
    # Inicializa gerador
    audio_gen = AudioGenerator()
    
    # Gera timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"output/audio/teste_sample_{timestamp}.mp3"
    
    try:
        audio_path = audio_gen.generate_audio(test_text, output_path)
        if audio_path and os.path.exists(audio_path):
            file_size = os.path.getsize(audio_path) / 1024
            print(f"‚úÖ √Åudio de teste gerado: {audio_path}")
            print(f"üìä Tamanho: {file_size:.1f} KB")
            return audio_path
        else:
            print("‚ùå Falha na gera√ß√£o de √°udio")
            return ""
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return ""

def save_sample_report(sample_path: str, analysis: dict, evaluation: dict) -> str:
    """Salva relat√≥rio do sample"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"sample_reports/report_{timestamp}.json"
    
    os.makedirs("sample_reports", exist_ok=True)
    
    report = {
        'timestamp': timestamp,
        'sample_path': sample_path,
        'analysis': analysis,
        'evaluation': evaluation,
        'approved': evaluation['approved']
    }
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    return report_path

def main():
    parser = argparse.ArgumentParser(description='Testa novo sample de voz')
    parser.add_argument('sample_path', help='Caminho para o arquivo de √°udio/v√≠deo')
    parser.add_argument('--text', help='Texto personalizado para teste de voz')
    parser.add_argument('--no-voice-test', action='store_true', help='Pula teste de gera√ß√£o de voz')
    
    args = parser.parse_args()
    
    sample_path = Path(args.sample_path)
    if not sample_path.exists():
        print(f"‚ùå Arquivo n√£o encontrado: {sample_path}")
        return
    
    print("üéôÔ∏è TESTE DE NOVO SAMPLE")
    print("=" * 50)
    print(f"üìÅ Arquivo: {sample_path.name}")
    
    # Extrai √°udio se for v√≠deo
    temp_dir = tempfile.mkdtemp()
    if sample_path.suffix.lower() in ['.mp4', '.mov', '.avi', '.mkv']:
        print("üé¨ Extraindo √°udio do v√≠deo...")
        audio_path = os.path.join(temp_dir, "sample_audio.wav")
        if not extract_audio_from_video(str(sample_path), audio_path):
            print("‚ùå Falha na extra√ß√£o de √°udio")
            return
    elif sample_path.suffix.lower() in ['.wav', '.mp3', '.m4a', '.opus', '.ogg', '.flac', '.aifc', '.aiff']:
        # Converte para WAV se necess√°rio
        audio_path = os.path.join(temp_dir, "sample_audio.wav")
        try:
            cmd = ['ffmpeg', '-i', str(sample_path), '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', audio_path, '-y']
            subprocess.run(cmd, capture_output=True, check=True)
        except Exception as e:
            print(f"‚ùå Falha na convers√£o de √°udio: {e}")
            return
    else:
        print("‚ùå Formato n√£o suportado. Use: mp4, mov, avi, mkv, wav, mp3, m4a, opus, ogg, flac, aifc, aiff")
        return
    
    # Analisa qualidade
    print("\nüîç Analisando qualidade do sample...")
    analysis = analyze_sample_quality(audio_path)
    
    if not analysis:
        print("‚ùå Falha na an√°lise")
        return
    
    # Avalia sample
    evaluation = evaluate_sample(analysis)
    
    # Mostra resultados
    print(f"\nüìä RESULTADO DA AN√ÅLISE")
    print("=" * 50)
    print(f"üéØ Score: {evaluation['score']}/100")
    print(f"üìã Status: {evaluation['recommendation']}")
    
    if evaluation['feedback']:
        print(f"\n‚úÖ Pontos Positivos:")
        for feedback in evaluation['feedback']:
            print(f"   {feedback}")
    
    if evaluation['issues']:
        print(f"\n‚ö†Ô∏è Problemas Encontrados:")
        for issue in evaluation['issues']:
            print(f"   {issue}")
    
    # Teste de voz (se aprovado e solicitado)
    if evaluation['approved'] and not args.no_voice_test:
        print(f"\nüéµ TESTE DE GERA√á√ÉO DE VOZ")
        print("=" * 50)
        test_audio = test_sample_voice_generation(str(sample_path), args.text)
        if test_audio:
            print(f"üéß Escute o resultado e compare com sua voz original!")
    elif not evaluation['approved']:
        print(f"\nüí° RECOMENDA√á√ïES PARA MELHORAR:")
        print("   ‚Ä¢ Grave em ambiente mais silencioso")
        print("   ‚Ä¢ Mantenha dist√¢ncia consistente do microfone")
        print("   ‚Ä¢ Fale de forma cont√≠nua, evite pausas longas")
        print("   ‚Ä¢ Dura√ß√£o ideal: 10-25 segundos")
        print("   ‚Ä¢ Regrave at√© conseguir score 60+")
    
    # Salva relat√≥rio
    report_path = save_sample_report(str(sample_path), analysis, evaluation)
    print(f"\nüìÑ Relat√≥rio salvo em: {report_path}")
    
    if evaluation['approved']:
        print(f"\nüéâ SAMPLE APROVADO! Pode usar para treinar o modelo.")
    else:
        print(f"\nüîÑ Regrave seguindo as recomenda√ß√µes acima.")

if __name__ == "__main__":
    main()